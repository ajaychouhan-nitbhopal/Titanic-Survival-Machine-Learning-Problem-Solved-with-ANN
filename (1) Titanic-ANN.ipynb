{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing raw train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       892\n",
       "1       893\n",
       "2       894\n",
       "3       895\n",
       "4       896\n",
       "       ... \n",
       "413    1305\n",
       "414    1306\n",
       "415    1307\n",
       "416    1308\n",
       "417    1309\n",
       "Name: PassengerId, Length: 418, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv') \n",
    "final = test['PassengerId']\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking missing values in train set\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking missing values in test set\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing \"\" to NaN in train\n",
    "train.replace('', np.nan, inplace = True)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing \"\" to NaN in test\n",
    "test.replace('', np.nan, inplace = True)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking missing values in train set\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see how many values are present in each label of Embarked column\n",
    "train['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is shwon that S is mode so we will replace all NaN values of column Embarked with 'S'\n",
    "# replacing the missing 'Embarked' values by the most frequent 'S'\n",
    "train[\"Embarked\"].replace(np.nan, \"S\", inplace=True)\n",
    "test[\"Embarked\"].replace(np.nan, \"S\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Age in train set: 29.69911764705882\n"
     ]
    }
   ],
   "source": [
    "# Finding average age of all passengers train set\n",
    "avg_age_train = train['Age'].astype('float').mean(axis=0)\n",
    "print(\"Average Age in train set:\", avg_age_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Age in test set: 30.272590361445783\n"
     ]
    }
   ],
   "source": [
    "# Finding average age of all passengers in test set\n",
    "avg_age_test = test['Age'].astype('float').mean(axis=0)\n",
    "print(\"Average Age in test set:\", avg_age_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing NaN values of Age column by the average age\n",
    "train['Age'].replace(np.nan, avg_age_train, inplace=True)\n",
    "test['Age'].replace(np.nan, avg_age_test, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping cabin columns in train and test\n",
    "\n",
    "train.drop(['Cabin','Name','Ticket','PassengerId'], axis=1, inplace = True)\n",
    "test.drop(['Cabin','Name','Ticket','PassengerId'], axis=1, inplace = True)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Fare in test set: 35.627188489208635\n"
     ]
    }
   ],
   "source": [
    "# Replacing rows of fare column in test set where values are NaN with average\n",
    "# finding average age of all passengers in test set\n",
    "avg_fare_test = test['Fare'].astype('float').mean(axis=0)\n",
    "print(\"Average Fare in test set:\", avg_fare_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing NaN values of Fare column by the average Fare\n",
    "test['Fare'].replace(np.nan, avg_fare_test, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  34.5      0      0   7.8292        Q\n",
       "1       3  female  47.0      1      0   7.0000        S\n",
       "2       2    male  62.0      0      0   9.6875        Q\n",
       "3       3    male  27.0      0      0   8.6625        S\n",
       "4       3  female  22.0      1      1  12.2875        S"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      int64\n",
       "Pclass        int64\n",
       "Sex          object\n",
       "Age         float64\n",
       "SibSp         int64\n",
       "Parch         int64\n",
       "Fare        float64\n",
       "Embarked     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking datatypes of all values in columns of train set\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing categorical values of Sex column by dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_variable_1_train = pd.get_dummies(train[\"Sex\"])\n",
    "dummy_variable_1_test = pd.get_dummies(test[\"Sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data frame \"df\" and \"dummy_variable_1\" \n",
    "train = pd.concat([train, dummy_variable_1_train], axis=1)\n",
    "test = pd.concat([test, dummy_variable_1_test], axis=1)\n",
    "# drop original column \"Sex\" from \"train and test\"\n",
    "train.drop(\"Sex\", axis = 1, inplace=True)\n",
    "test.drop(\"Sex\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing categorical values of Embarked column by dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_variable_2_train = pd.get_dummies(train[\"Embarked\"])\n",
    "dummy_variable_2_test = pd.get_dummies(test[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data frame \"df\" and \"dummy_variable_1\" \n",
    "train = pd.concat([train, dummy_variable_2_train], axis=1)\n",
    "test = pd.concat([test, dummy_variable_2_test], axis=1)\n",
    "# drop original column \"fuel-type\" from \"df\"\n",
    "train.drop(\"Embarked\", axis = 1, inplace=True)\n",
    "test.drop(\"Embarked\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  female  male  C  Q  S\n",
       "0         0       3  22.0      1      0   7.2500       0     1  0  0  1\n",
       "1         1       1  38.0      1      0  71.2833       1     0  1  0  0\n",
       "2         1       3  26.0      0      0   7.9250       1     0  0  0  1\n",
       "3         1       1  35.0      1      0  53.1000       1     0  0  0  1\n",
       "4         0       3  35.0      0      0   8.0500       0     1  0  0  1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  female  male  C  Q  S\n",
       "0       3  34.5      0      0   7.8292       0     1  0  1  0\n",
       "1       3  47.0      1      0   7.0000       1     0  0  0  1\n",
       "2       2  62.0      0      0   9.6875       0     1  0  1  0\n",
       "3       3  27.0      0      0   8.6625       0     1  0  0  1\n",
       "4       3  22.0      1      1  12.2875       1     0  0  0  1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,1:].values\n",
    "y_train = train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass    0\n",
       "Age       0\n",
       "SibSp     0\n",
       "Parch     0\n",
       "Fare      0\n",
       "female    0\n",
       "male      0\n",
       "C         0\n",
       "Q         0\n",
       "S         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.iloc[:,:]\n",
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further splitting X_train into X_train_train and X_train_test for gaining more insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_train,X_train_test,y_train_train,y_train_test = train_test_split(X_train,y_train, test_size = 0.25, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.56610693,  0.        , -0.4745452 , ..., -0.48204268,\n",
       "        -0.30756234,  0.61583843],\n",
       "       [ 0.82737724, -0.36161755, -0.4745452 , ..., -0.48204268,\n",
       "        -0.30756234,  0.61583843],\n",
       "       [-0.36936484, -0.4385719 , -0.4745452 , ..., -0.48204268,\n",
       "        -0.30756234,  0.61583843],\n",
       "       ...,\n",
       "       [ 0.82737724,  0.86965206,  1.34013193, ..., -0.48204268,\n",
       "        -0.30756234,  0.61583843],\n",
       "       [-1.56610693, -1.20811541,  0.43279337, ..., -0.48204268,\n",
       "        -0.30756234,  0.61583843],\n",
       "       [-1.56610693, -0.66943495, -0.4745452 , ..., -0.48204268,\n",
       "        -0.30756234,  0.61583843]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82737724,  0.        ,  0.43279337, ...,  2.0745051 ,\n",
       "        -0.30756234, -1.62380254],\n",
       "       [-0.36936484,  0.10010856, -0.4745452 , ..., -0.48204268,\n",
       "        -0.30756234,  0.61583843],\n",
       "       [ 0.82737724, -0.7463893 , -0.4745452 , ..., -0.48204268,\n",
       "        -0.30756234,  0.61583843],\n",
       "       ...,\n",
       "       [ 0.82737724,  0.        , -0.4745452 , ..., -0.48204268,\n",
       "        -0.30756234,  0.61583843],\n",
       "       [-0.36936484, -0.4385719 , -0.4745452 , ..., -0.48204268,\n",
       "        -0.30756234,  0.61583843],\n",
       "       [ 0.82737724, -0.900298  ,  0.43279337, ..., -0.48204268,\n",
       "        -0.30756234,  0.61583843]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intitializing ann\n",
    "import tensorflow as tf\n",
    "ann = tf.keras.models.Sequential() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer and hidden layer 1\n",
    "ann.add(tf.keras.layers.Dense(units = 14, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hidden layer 2\n",
    "ann.add(tf.keras.layers.Dense(units = 14, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "ann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing by Adam Optimizer, 'binary_crossentropy' is selected as Loss function\n",
    "# accuracy is selected as metrics\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 668 samples\n",
      "Epoch 1/100\n",
      "668/668 [==============================] - 1s 2ms/sample - loss: 0.6683 - accuracy: 0.6183\n",
      "Epoch 2/100\n",
      "668/668 [==============================] - 0s 228us/sample - loss: 0.5425 - accuracy: 0.7725\n",
      "Epoch 3/100\n",
      "668/668 [==============================] - 0s 228us/sample - loss: 0.4728 - accuracy: 0.7979\n",
      "Epoch 4/100\n",
      "668/668 [==============================] - 0s 251us/sample - loss: 0.4521 - accuracy: 0.7994\n",
      "Epoch 5/100\n",
      "668/668 [==============================] - 0s 263us/sample - loss: 0.4432 - accuracy: 0.8069\n",
      "Epoch 6/100\n",
      "668/668 [==============================] - 0s 251us/sample - loss: 0.4372 - accuracy: 0.8069\n",
      "Epoch 7/100\n",
      "668/668 [==============================] - 0s 192us/sample - loss: 0.4325 - accuracy: 0.8114\n",
      "Epoch 8/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.4283 - accuracy: 0.8159\n",
      "Epoch 9/100\n",
      "668/668 [==============================] - 0s 192us/sample - loss: 0.4266 - accuracy: 0.8174\n",
      "Epoch 10/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.4229 - accuracy: 0.8249\n",
      "Epoch 11/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.4188 - accuracy: 0.8249\n",
      "Epoch 12/100\n",
      "668/668 [==============================] - 0s 192us/sample - loss: 0.4174 - accuracy: 0.8263\n",
      "Epoch 13/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.4151 - accuracy: 0.8234\n",
      "Epoch 14/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.4135 - accuracy: 0.8219\n",
      "Epoch 15/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.4117 - accuracy: 0.8278\n",
      "Epoch 16/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.4095 - accuracy: 0.8263\n",
      "Epoch 17/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.4091 - accuracy: 0.8293\n",
      "Epoch 18/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.4071 - accuracy: 0.8263\n",
      "Epoch 19/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.4059 - accuracy: 0.8249\n",
      "Epoch 20/100\n",
      "668/668 [==============================] - 0s 192us/sample - loss: 0.4051 - accuracy: 0.8293\n",
      "Epoch 21/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.4050 - accuracy: 0.8368\n",
      "Epoch 22/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.4029 - accuracy: 0.8263\n",
      "Epoch 23/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.4026 - accuracy: 0.8293\n",
      "Epoch 24/100\n",
      "668/668 [==============================] - 0s 192us/sample - loss: 0.4002 - accuracy: 0.8338\n",
      "Epoch 25/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.4012 - accuracy: 0.8308\n",
      "Epoch 26/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3987 - accuracy: 0.8368\n",
      "Epoch 27/100\n",
      "668/668 [==============================] - 0s 192us/sample - loss: 0.3976 - accuracy: 0.8383\n",
      "Epoch 28/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.3966 - accuracy: 0.8383\n",
      "Epoch 29/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3956 - accuracy: 0.8398\n",
      "Epoch 30/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3940 - accuracy: 0.8353\n",
      "Epoch 31/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3926 - accuracy: 0.8353\n",
      "Epoch 32/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.3931 - accuracy: 0.8338\n",
      "Epoch 33/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3924 - accuracy: 0.8368\n",
      "Epoch 34/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3918 - accuracy: 0.8353\n",
      "Epoch 35/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3908 - accuracy: 0.8428\n",
      "Epoch 36/100\n",
      "668/668 [==============================] - 0s 192us/sample - loss: 0.3894 - accuracy: 0.8353\n",
      "Epoch 37/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.3911 - accuracy: 0.8398\n",
      "Epoch 38/100\n",
      "668/668 [==============================] - 0s 192us/sample - loss: 0.3874 - accuracy: 0.8383\n",
      "Epoch 39/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3876 - accuracy: 0.8458\n",
      "Epoch 40/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3871 - accuracy: 0.8383\n",
      "Epoch 41/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3861 - accuracy: 0.8323\n",
      "Epoch 42/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3863 - accuracy: 0.8428\n",
      "Epoch 43/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3846 - accuracy: 0.8383\n",
      "Epoch 44/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3865 - accuracy: 0.8398\n",
      "Epoch 45/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3842 - accuracy: 0.8353\n",
      "Epoch 46/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.3837 - accuracy: 0.8398\n",
      "Epoch 47/100\n",
      "668/668 [==============================] - 0s 287us/sample - loss: 0.3822 - accuracy: 0.8383\n",
      "Epoch 48/100\n",
      "668/668 [==============================] - 0s 240us/sample - loss: 0.3816 - accuracy: 0.8413\n",
      "Epoch 49/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.3804 - accuracy: 0.8413\n",
      "Epoch 50/100\n",
      "668/668 [==============================] - 0s 228us/sample - loss: 0.3791 - accuracy: 0.8458\n",
      "Epoch 51/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.3788 - accuracy: 0.8458\n",
      "Epoch 52/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.3788 - accuracy: 0.8383\n",
      "Epoch 53/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.3765 - accuracy: 0.83 - 0s 204us/sample - loss: 0.3791 - accuracy: 0.8368\n",
      "Epoch 54/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3787 - accuracy: 0.8443\n",
      "Epoch 55/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3778 - accuracy: 0.8413\n",
      "Epoch 56/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.3765 - accuracy: 0.8413\n",
      "Epoch 57/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3784 - accuracy: 0.8428\n",
      "Epoch 58/100\n",
      "668/668 [==============================] - 0s 228us/sample - loss: 0.3749 - accuracy: 0.8443\n",
      "Epoch 59/100\n",
      "668/668 [==============================] - 0s 228us/sample - loss: 0.3748 - accuracy: 0.8458\n",
      "Epoch 60/100\n",
      "668/668 [==============================] - 0s 299us/sample - loss: 0.3746 - accuracy: 0.8428\n",
      "Epoch 61/100\n",
      "668/668 [==============================] - 0s 263us/sample - loss: 0.3736 - accuracy: 0.8503\n",
      "Epoch 62/100\n",
      "668/668 [==============================] - 0s 228us/sample - loss: 0.3734 - accuracy: 0.8488\n",
      "Epoch 63/100\n",
      "668/668 [==============================] - 0s 228us/sample - loss: 0.3731 - accuracy: 0.8473\n",
      "Epoch 64/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.3714 - accuracy: 0.8443\n",
      "Epoch 65/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3723 - accuracy: 0.8473\n",
      "Epoch 66/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3730 - accuracy: 0.8443\n",
      "Epoch 67/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3704 - accuracy: 0.8428\n",
      "Epoch 68/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3715 - accuracy: 0.8443\n",
      "Epoch 69/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3688 - accuracy: 0.8473\n",
      "Epoch 70/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3721 - accuracy: 0.8473\n",
      "Epoch 71/100\n",
      "668/668 [==============================] - 0s 192us/sample - loss: 0.3687 - accuracy: 0.8443\n",
      "Epoch 72/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.3673 - accuracy: 0.8458\n",
      "Epoch 73/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3671 - accuracy: 0.8443\n",
      "Epoch 74/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3666 - accuracy: 0.8488\n",
      "Epoch 75/100\n",
      "668/668 [==============================] - 0s 228us/sample - loss: 0.3656 - accuracy: 0.8503\n",
      "Epoch 76/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3645 - accuracy: 0.8488\n",
      "Epoch 77/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3655 - accuracy: 0.8473\n",
      "Epoch 78/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3655 - accuracy: 0.8518\n",
      "Epoch 79/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.3653 - accuracy: 0.8503\n",
      "Epoch 80/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.3644 - accuracy: 0.8473\n",
      "Epoch 81/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3633 - accuracy: 0.8503\n",
      "Epoch 82/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3644 - accuracy: 0.8503\n",
      "Epoch 83/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3631 - accuracy: 0.8518\n",
      "Epoch 84/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.3612 - accuracy: 0.8458\n",
      "Epoch 85/100\n",
      "668/668 [==============================] - 0s 204us/sample - loss: 0.3614 - accuracy: 0.8473 - loss: 0.3696 - accuracy: 0.\n",
      "Epoch 86/100\n",
      "668/668 [==============================] - 0s 216us/sample - loss: 0.3608 - accuracy: 0.8473\n",
      "Epoch 87/100\n",
      "668/668 [==============================] - 0s 275us/sample - loss: 0.3594 - accuracy: 0.8488\n",
      "Epoch 88/100\n",
      "668/668 [==============================] - 0s 337us/sample - loss: 0.3604 - accuracy: 0.8488\n",
      "Epoch 89/100\n",
      "668/668 [==============================] - 0s 263us/sample - loss: 0.3589 - accuracy: 0.8458\n",
      "Epoch 90/100\n",
      "668/668 [==============================] - 0s 255us/sample - loss: 0.3602 - accuracy: 0.8533\n",
      "Epoch 91/100\n",
      "668/668 [==============================] - 0s 232us/sample - loss: 0.3587 - accuracy: 0.8428\n",
      "Epoch 92/100\n",
      "668/668 [==============================] - 0s 219us/sample - loss: 0.3583 - accuracy: 0.8503\n",
      "Epoch 93/100\n",
      "668/668 [==============================] - 0s 231us/sample - loss: 0.3581 - accuracy: 0.8473\n",
      "Epoch 94/100\n",
      "668/668 [==============================] - 0s 230us/sample - loss: 0.3585 - accuracy: 0.8503\n",
      "Epoch 95/100\n",
      "668/668 [==============================] - 0s 213us/sample - loss: 0.3595 - accuracy: 0.8443\n",
      "Epoch 96/100\n",
      "668/668 [==============================] - 0s 221us/sample - loss: 0.3559 - accuracy: 0.8428\n",
      "Epoch 97/100\n",
      "668/668 [==============================] - 0s 246us/sample - loss: 0.3561 - accuracy: 0.8443\n",
      "Epoch 98/100\n",
      "668/668 [==============================] - 0s 224us/sample - loss: 0.3555 - accuracy: 0.8488\n",
      "Epoch 99/100\n",
      "668/668 [==============================] - 0s 223us/sample - loss: 0.3549 - accuracy: 0.8488\n",
      "Epoch 100/100\n",
      "668/668 [==============================] - 0s 232us/sample - loss: 0.3565 - accuracy: 0.8473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d1e3b61d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting X_train_train and y_train_train in our model\n",
    "ann.fit(X_train_train, y_train_train, batch_size = 8, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Train set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = ann.predict(X_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold is set to 0.5\n",
    "y_pred_train = (y_pred_train > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix and Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[394  21]\n",
      " [ 78 175]]\n",
      "Accuracy of the model is 0.8517964071856288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm1 = confusion_matrix(y_train_train, y_pred_train)\n",
    "print(\"Confusion Matrix:\", cm1)\n",
    "print(\"Accuracy of the model is\", accuracy_score(y_train_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# Defining th function for plotting Confusion Matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Set Accuracy and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       415\n",
      "           1       0.89      0.69      0.78       253\n",
      "\n",
      "    accuracy                           0.85       668\n",
      "   macro avg       0.86      0.82      0.83       668\n",
      "weighted avg       0.86      0.85      0.85       668\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[394  21]\n",
      " [ 78 175]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_train_train, y_pred_train, labels=[0,1])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print (classification_report(y_train_train, y_pred_train))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Not Survived(0)','Survived(1)'], normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(X_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_train_test.reshape(len(y_train_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126   8]\n",
      " [ 25  64]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.852017937219731"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_train_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_train_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Accuracy and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       134\n",
      "           1       0.89      0.72      0.80        89\n",
      "\n",
      "    accuracy                           0.85       223\n",
      "   macro avg       0.86      0.83      0.84       223\n",
      "weighted avg       0.86      0.85      0.85       223\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[126   8]\n",
      " [ 25  64]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_train_test, y_pred, labels=[0,1])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print (classification_report(y_train_test, y_pred))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Not Survived(0)','Survived(1)'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "y_pred = y_pred.reshape(len(y_pred),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "passangerid = np.asarray(final)\n",
    "passangerid = passangerid.reshape(len(passangerid),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 892,    0],\n",
       "       [ 893,    0],\n",
       "       [ 894,    0],\n",
       "       [ 895,    0],\n",
       "       [ 896,    0],\n",
       "       [ 897,    0],\n",
       "       [ 898,    1],\n",
       "       [ 899,    0],\n",
       "       [ 900,    1],\n",
       "       [ 901,    0],\n",
       "       [ 902,    0],\n",
       "       [ 903,    0],\n",
       "       [ 904,    1],\n",
       "       [ 905,    0],\n",
       "       [ 906,    1],\n",
       "       [ 907,    1],\n",
       "       [ 908,    0],\n",
       "       [ 909,    0],\n",
       "       [ 910,    0],\n",
       "       [ 911,    0],\n",
       "       [ 912,    0],\n",
       "       [ 913,    1],\n",
       "       [ 914,    1],\n",
       "       [ 915,    1],\n",
       "       [ 916,    1],\n",
       "       [ 917,    0],\n",
       "       [ 918,    1],\n",
       "       [ 919,    0],\n",
       "       [ 920,    0],\n",
       "       [ 921,    0],\n",
       "       [ 922,    0],\n",
       "       [ 923,    0],\n",
       "       [ 924,    0],\n",
       "       [ 925,    0],\n",
       "       [ 926,    0],\n",
       "       [ 927,    0],\n",
       "       [ 928,    0],\n",
       "       [ 929,    0],\n",
       "       [ 930,    0],\n",
       "       [ 931,    0],\n",
       "       [ 932,    0],\n",
       "       [ 933,    0],\n",
       "       [ 934,    0],\n",
       "       [ 935,    1],\n",
       "       [ 936,    1],\n",
       "       [ 937,    0],\n",
       "       [ 938,    0],\n",
       "       [ 939,    0],\n",
       "       [ 940,    1],\n",
       "       [ 941,    0],\n",
       "       [ 942,    0],\n",
       "       [ 943,    0],\n",
       "       [ 944,    1],\n",
       "       [ 945,    1],\n",
       "       [ 946,    0],\n",
       "       [ 947,    0],\n",
       "       [ 948,    0],\n",
       "       [ 949,    0],\n",
       "       [ 950,    0],\n",
       "       [ 951,    1],\n",
       "       [ 952,    0],\n",
       "       [ 953,    0],\n",
       "       [ 954,    0],\n",
       "       [ 955,    1],\n",
       "       [ 956,    0],\n",
       "       [ 957,    1],\n",
       "       [ 958,    1],\n",
       "       [ 959,    0],\n",
       "       [ 960,    0],\n",
       "       [ 961,    1],\n",
       "       [ 962,    1],\n",
       "       [ 963,    0],\n",
       "       [ 964,    0],\n",
       "       [ 965,    0],\n",
       "       [ 966,    1],\n",
       "       [ 967,    0],\n",
       "       [ 968,    0],\n",
       "       [ 969,    1],\n",
       "       [ 970,    0],\n",
       "       [ 971,    1],\n",
       "       [ 972,    1],\n",
       "       [ 973,    1],\n",
       "       [ 974,    0],\n",
       "       [ 975,    0],\n",
       "       [ 976,    0],\n",
       "       [ 977,    0],\n",
       "       [ 978,    1],\n",
       "       [ 979,    0],\n",
       "       [ 980,    1],\n",
       "       [ 981,    1],\n",
       "       [ 982,    0],\n",
       "       [ 983,    0],\n",
       "       [ 984,    1],\n",
       "       [ 985,    0],\n",
       "       [ 986,    0],\n",
       "       [ 987,    0],\n",
       "       [ 988,    1],\n",
       "       [ 989,    0],\n",
       "       [ 990,    0],\n",
       "       [ 991,    0],\n",
       "       [ 992,    1],\n",
       "       [ 993,    0],\n",
       "       [ 994,    0],\n",
       "       [ 995,    0],\n",
       "       [ 996,    1],\n",
       "       [ 997,    0],\n",
       "       [ 998,    0],\n",
       "       [ 999,    0],\n",
       "       [1000,    0],\n",
       "       [1001,    0],\n",
       "       [1002,    0],\n",
       "       [1003,    1],\n",
       "       [1004,    1],\n",
       "       [1005,    1],\n",
       "       [1006,    1],\n",
       "       [1007,    0],\n",
       "       [1008,    0],\n",
       "       [1009,    1],\n",
       "       [1010,    0],\n",
       "       [1011,    1],\n",
       "       [1012,    1],\n",
       "       [1013,    0],\n",
       "       [1014,    1],\n",
       "       [1015,    0],\n",
       "       [1016,    0],\n",
       "       [1017,    1],\n",
       "       [1018,    0],\n",
       "       [1019,    1],\n",
       "       [1020,    0],\n",
       "       [1021,    0],\n",
       "       [1022,    0],\n",
       "       [1023,    0],\n",
       "       [1024,    0],\n",
       "       [1025,    0],\n",
       "       [1026,    0],\n",
       "       [1027,    0],\n",
       "       [1028,    0],\n",
       "       [1029,    0],\n",
       "       [1030,    0],\n",
       "       [1031,    0],\n",
       "       [1032,    0],\n",
       "       [1033,    1],\n",
       "       [1034,    0],\n",
       "       [1035,    0],\n",
       "       [1036,    0],\n",
       "       [1037,    0],\n",
       "       [1038,    0],\n",
       "       [1039,    0],\n",
       "       [1040,    0],\n",
       "       [1041,    0],\n",
       "       [1042,    1],\n",
       "       [1043,    0],\n",
       "       [1044,    0],\n",
       "       [1045,    0],\n",
       "       [1046,    0],\n",
       "       [1047,    0],\n",
       "       [1048,    1],\n",
       "       [1049,    0],\n",
       "       [1050,    0],\n",
       "       [1051,    1],\n",
       "       [1052,    1],\n",
       "       [1053,    1],\n",
       "       [1054,    1],\n",
       "       [1055,    0],\n",
       "       [1056,    0],\n",
       "       [1057,    0],\n",
       "       [1058,    0],\n",
       "       [1059,    0],\n",
       "       [1060,    1],\n",
       "       [1061,    0],\n",
       "       [1062,    0],\n",
       "       [1063,    0],\n",
       "       [1064,    0],\n",
       "       [1065,    0],\n",
       "       [1066,    0],\n",
       "       [1067,    1],\n",
       "       [1068,    1],\n",
       "       [1069,    0],\n",
       "       [1070,    1],\n",
       "       [1071,    1],\n",
       "       [1072,    0],\n",
       "       [1073,    0],\n",
       "       [1074,    1],\n",
       "       [1075,    0],\n",
       "       [1076,    1],\n",
       "       [1077,    0],\n",
       "       [1078,    1],\n",
       "       [1079,    0],\n",
       "       [1080,    0],\n",
       "       [1081,    0],\n",
       "       [1082,    0],\n",
       "       [1083,    0],\n",
       "       [1084,    1],\n",
       "       [1085,    0],\n",
       "       [1086,    1],\n",
       "       [1087,    0],\n",
       "       [1088,    1],\n",
       "       [1089,    0],\n",
       "       [1090,    0],\n",
       "       [1091,    0],\n",
       "       [1092,    1],\n",
       "       [1093,    1],\n",
       "       [1094,    1],\n",
       "       [1095,    1],\n",
       "       [1096,    0],\n",
       "       [1097,    0],\n",
       "       [1098,    1],\n",
       "       [1099,    0],\n",
       "       [1100,    1],\n",
       "       [1101,    0],\n",
       "       [1102,    0],\n",
       "       [1103,    0],\n",
       "       [1104,    0],\n",
       "       [1105,    1],\n",
       "       [1106,    0],\n",
       "       [1107,    0],\n",
       "       [1108,    1],\n",
       "       [1109,    0],\n",
       "       [1110,    1],\n",
       "       [1111,    0],\n",
       "       [1112,    1],\n",
       "       [1113,    0],\n",
       "       [1114,    1],\n",
       "       [1115,    0],\n",
       "       [1116,    1],\n",
       "       [1117,    1],\n",
       "       [1118,    0],\n",
       "       [1119,    1],\n",
       "       [1120,    0],\n",
       "       [1121,    0],\n",
       "       [1122,    0],\n",
       "       [1123,    1],\n",
       "       [1124,    0],\n",
       "       [1125,    0],\n",
       "       [1126,    0],\n",
       "       [1127,    0],\n",
       "       [1128,    1],\n",
       "       [1129,    0],\n",
       "       [1130,    1],\n",
       "       [1131,    1],\n",
       "       [1132,    1],\n",
       "       [1133,    1],\n",
       "       [1134,    0],\n",
       "       [1135,    0],\n",
       "       [1136,    0],\n",
       "       [1137,    0],\n",
       "       [1138,    1],\n",
       "       [1139,    0],\n",
       "       [1140,    1],\n",
       "       [1141,    0],\n",
       "       [1142,    1],\n",
       "       [1143,    0],\n",
       "       [1144,    0],\n",
       "       [1145,    0],\n",
       "       [1146,    0],\n",
       "       [1147,    0],\n",
       "       [1148,    0],\n",
       "       [1149,    0],\n",
       "       [1150,    1],\n",
       "       [1151,    0],\n",
       "       [1152,    0],\n",
       "       [1153,    0],\n",
       "       [1154,    1],\n",
       "       [1155,    1],\n",
       "       [1156,    0],\n",
       "       [1157,    0],\n",
       "       [1158,    0],\n",
       "       [1159,    0],\n",
       "       [1160,    0],\n",
       "       [1161,    0],\n",
       "       [1162,    0],\n",
       "       [1163,    0],\n",
       "       [1164,    1],\n",
       "       [1165,    1],\n",
       "       [1166,    0],\n",
       "       [1167,    1],\n",
       "       [1168,    0],\n",
       "       [1169,    0],\n",
       "       [1170,    0],\n",
       "       [1171,    0],\n",
       "       [1172,    0],\n",
       "       [1173,    1],\n",
       "       [1174,    1],\n",
       "       [1175,    1],\n",
       "       [1176,    1],\n",
       "       [1177,    0],\n",
       "       [1178,    0],\n",
       "       [1179,    0],\n",
       "       [1180,    0],\n",
       "       [1181,    0],\n",
       "       [1182,    0],\n",
       "       [1183,    1],\n",
       "       [1184,    0],\n",
       "       [1185,    0],\n",
       "       [1186,    0],\n",
       "       [1187,    0],\n",
       "       [1188,    1],\n",
       "       [1189,    0],\n",
       "       [1190,    0],\n",
       "       [1191,    0],\n",
       "       [1192,    0],\n",
       "       [1193,    0],\n",
       "       [1194,    0],\n",
       "       [1195,    0],\n",
       "       [1196,    1],\n",
       "       [1197,    1],\n",
       "       [1198,    0],\n",
       "       [1199,    1],\n",
       "       [1200,    0],\n",
       "       [1201,    1],\n",
       "       [1202,    0],\n",
       "       [1203,    0],\n",
       "       [1204,    0],\n",
       "       [1205,    1],\n",
       "       [1206,    1],\n",
       "       [1207,    1],\n",
       "       [1208,    1],\n",
       "       [1209,    0],\n",
       "       [1210,    0],\n",
       "       [1211,    0],\n",
       "       [1212,    0],\n",
       "       [1213,    0],\n",
       "       [1214,    0],\n",
       "       [1215,    0],\n",
       "       [1216,    1],\n",
       "       [1217,    0],\n",
       "       [1218,    1],\n",
       "       [1219,    0],\n",
       "       [1220,    0],\n",
       "       [1221,    0],\n",
       "       [1222,    1],\n",
       "       [1223,    0],\n",
       "       [1224,    0],\n",
       "       [1225,    1],\n",
       "       [1226,    0],\n",
       "       [1227,    0],\n",
       "       [1228,    0],\n",
       "       [1229,    0],\n",
       "       [1230,    0],\n",
       "       [1231,    0],\n",
       "       [1232,    0],\n",
       "       [1233,    0],\n",
       "       [1234,    0],\n",
       "       [1235,    1],\n",
       "       [1236,    0],\n",
       "       [1237,    1],\n",
       "       [1238,    0],\n",
       "       [1239,    0],\n",
       "       [1240,    0],\n",
       "       [1241,    1],\n",
       "       [1242,    1],\n",
       "       [1243,    0],\n",
       "       [1244,    0],\n",
       "       [1245,    0],\n",
       "       [1246,    1],\n",
       "       [1247,    0],\n",
       "       [1248,    1],\n",
       "       [1249,    0],\n",
       "       [1250,    0],\n",
       "       [1251,    0],\n",
       "       [1252,    0],\n",
       "       [1253,    1],\n",
       "       [1254,    1],\n",
       "       [1255,    0],\n",
       "       [1256,    1],\n",
       "       [1257,    0],\n",
       "       [1258,    0],\n",
       "       [1259,    1],\n",
       "       [1260,    1],\n",
       "       [1261,    0],\n",
       "       [1262,    0],\n",
       "       [1263,    1],\n",
       "       [1264,    0],\n",
       "       [1265,    0],\n",
       "       [1266,    1],\n",
       "       [1267,    1],\n",
       "       [1268,    0],\n",
       "       [1269,    0],\n",
       "       [1270,    0],\n",
       "       [1271,    0],\n",
       "       [1272,    0],\n",
       "       [1273,    0],\n",
       "       [1274,    0],\n",
       "       [1275,    0],\n",
       "       [1276,    0],\n",
       "       [1277,    1],\n",
       "       [1278,    0],\n",
       "       [1279,    0],\n",
       "       [1280,    0],\n",
       "       [1281,    0],\n",
       "       [1282,    0],\n",
       "       [1283,    1],\n",
       "       [1284,    1],\n",
       "       [1285,    0],\n",
       "       [1286,    0],\n",
       "       [1287,    1],\n",
       "       [1288,    0],\n",
       "       [1289,    1],\n",
       "       [1290,    0],\n",
       "       [1291,    0],\n",
       "       [1292,    1],\n",
       "       [1293,    0],\n",
       "       [1294,    1],\n",
       "       [1295,    0],\n",
       "       [1296,    0],\n",
       "       [1297,    0],\n",
       "       [1298,    0],\n",
       "       [1299,    1],\n",
       "       [1300,    1],\n",
       "       [1301,    1],\n",
       "       [1302,    1],\n",
       "       [1303,    1],\n",
       "       [1304,    0],\n",
       "       [1305,    0],\n",
       "       [1306,    1],\n",
       "       [1307,    0],\n",
       "       [1308,    0],\n",
       "       [1309,    0]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final result for the test set\n",
    "final_array = np.concatenate((passangerid, y_pred),axis=1)\n",
    "final_array\n",
    "\n",
    "# NOTE - By submitting this result to Kaggle's Machine Learning Problem I got 0.78468 Accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
